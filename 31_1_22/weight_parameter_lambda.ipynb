{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9522458",
   "metadata": {},
   "source": [
    "### Determining the weight parameter lambda\n",
    "\n",
    "31/1/22\n",
    "\n",
    "Aryaman Sharma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05197a01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvVAE(\n",
       "  (encoder): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (1): ResBlock_Down(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.2)\n",
       "      )\n",
       "    )\n",
       "    (2): ResBlock_Down(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.2)\n",
       "      )\n",
       "    )\n",
       "    (3): ResBlock_Down(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.2)\n",
       "      )\n",
       "    )\n",
       "    (4): ResBlock_Down(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.2)\n",
       "      )\n",
       "    )\n",
       "    (5): ResBlock_Down(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.2)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (res_encoder): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "    (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): LeakyReLU(negative_slope=0.2)\n",
       "    (4): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): LeakyReLU(negative_slope=0.2)\n",
       "    (7): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "    (8): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): LeakyReLU(negative_slope=0.2)\n",
       "    (10): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "  )\n",
       "  (fc1): ResBlock_Down(\n",
       "    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (fc2): ResBlock_Down(\n",
       "    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): ResBlock_Up(\n",
       "      (conv1): Sequential(\n",
       "        (0): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "        (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Sequential(\n",
       "        (0): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "        (1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Upsample(scale_factor=4.0, mode=bilinear)\n",
       "        (1): Conv2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResBlock_Up(\n",
       "      (conv1): Sequential(\n",
       "        (0): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Sequential(\n",
       "        (0): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "        (1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Upsample(scale_factor=4.0, mode=bilinear)\n",
       "        (1): Conv2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): ResBlock_Up(\n",
       "      (conv1): Sequential(\n",
       "        (0): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Sequential(\n",
       "        (0): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "        (1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Upsample(scale_factor=4.0, mode=bilinear)\n",
       "        (1): Conv2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): ResBlock_Up(\n",
       "      (conv1): Sequential(\n",
       "        (0): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "        (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Sequential(\n",
       "        (0): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "        (1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Upsample(scale_factor=4.0, mode=bilinear)\n",
       "        (1): Conv2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): ResBlock_Up(\n",
       "      (conv1): Sequential(\n",
       "        (0): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "        (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Sequential(\n",
       "        (0): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "        (1): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Upsample(scale_factor=4.0, mode=bilinear)\n",
       "        (1): Conv2d(32, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): ResBlock_Up(\n",
       "      (conv1): Sequential(\n",
       "        (0): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "        (1): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Sequential(\n",
       "        (0): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "        (1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Upsample(scale_factor=4.0, mode=bilinear)\n",
       "        (1): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): LeakyReLU(negative_slope=0.2)\n",
       "    (9): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import skimage.exposure\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as tfs\n",
    "import torch.optim as optim\n",
    "import random\n",
    "device='cuda'\n",
    "vae_path = '/home/Student/s4606685/24_1_22/logsnormalised100.pth'\n",
    "vae_model = torch.load(vae_path, map_location=torch.device('cuda'))\n",
    "vae_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d0fb3a",
   "metadata": {},
   "source": [
    "## Req fns. Note we load from training data only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "237029d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_training_image():\n",
    "    images_all = os.listdir('/home/Student/s4606685/summer_research/oasis-3/png_data/T1w-png-converted')\n",
    "    random_image = random.randint(0, len(images_all))\n",
    "    image_path = '/home/Student/s4606685/summer_research/oasis-3/png_data/T1w-png-converted/' + images_all[random_image]\n",
    "    img = Image.open(image_path)\n",
    "    img = img.convert('L')\n",
    "    img = img.resize((128, 128))\n",
    "    img = np.array(img)\n",
    "    img = (img - np.min(img)) / (np.max(img) - np.min(img))\n",
    "    img = np.expand_dims(img, axis=-1)\n",
    "    tensor_transform = tfs.Compose([\n",
    "        tfs.ToTensor(),\n",
    "    ])\n",
    "    img = tensor_transform(img)\n",
    "    img = img.unsqueeze(0) # (1,1,128,128) tensor\n",
    "    return img\n",
    "\n",
    "def total_variation(images):\n",
    "    \"\"\"\n",
    "    Edited from tensorflow implementation\n",
    "    Calculate and return the total variation for one or more images.\n",
    "    The total variation is the sum of the absolute differences for neighboring\n",
    "    pixel-values in the input images. This measures how much noise is in the\n",
    "    images.\n",
    "    This implements the anisotropic 2-D version of the formula described here:\n",
    "    https://en.wikipedia.org/wiki/Total_variation_denoising\n",
    "    Args:\n",
    "        images: 3-D Tensor of shape `[batch, height, width]`.\n",
    "    Returns:\n",
    "        The total variation of `images`.\n",
    "        return a scalar float with the total variation for\n",
    "        that image.\n",
    "    \"\"\"\n",
    "\n",
    "    # The input is a single image with shape [batch, height, width].\n",
    "\n",
    "    # Calculate the difference of neighboring pixel-values.\n",
    "    # The images are shifted one pixel along the height and width by slicing.\n",
    "    pixel_dif1 = images[:, 1:, :] - images[:, :-1, :]\n",
    "    pixel_dif2 = images[:, :, 1:] - images[:, :, :-1]\n",
    "\n",
    "    # Sum for all axis. (None is an alias for all axis.)\n",
    "\n",
    "    # Calculate the total variation by taking the absolute value of the\n",
    "    # pixel-differences and summing over the appropriate axis.\n",
    "    tot_var = (\n",
    "        torch.sum(torch.abs(pixel_dif1)) +\n",
    "        torch.sum(torch.abs(pixel_dif2)))\n",
    "    return tot_var\n",
    "\n",
    "def map_restoration(input_img, dec_mu, riter=100, weight=1, step_size=0.003):\n",
    "    input_img = nn.Parameter(input_img, requires_grad=False)\n",
    "    dec_mu = nn.Parameter(dec_mu.float(), requires_grad=False)\n",
    "    img_ano = nn.Parameter(input_img.clone(), requires_grad=True)\n",
    "    input_img = input_img.to(device)\n",
    "    dec_mu = dec_mu.to(device)\n",
    "    img_ano = img_ano.to(device)\n",
    "    MAP_optimizer = optim.Adam([img_ano], lr=step_size)\n",
    "    for i in range(riter):\n",
    "        _, z_mean, z_cov, _ = vae_model(img_ano.unsqueeze(1).double()) \n",
    "        l2_loss = (dec_mu.view(-1, dec_mu.numel()) - img_ano.view(-1, img_ano.numel())).pow(2)\n",
    "        kl_loss = -0.5 * torch.sum(1 + z_cov - z_mean.pow(2) - z_cov.exp())\n",
    "        gfunc = torch.sum(l2_loss) + kl_loss + weight*total_variation(img_ano-input_img)\n",
    "        gfunc.backward()\n",
    "        torch.clamp(img_ano, -100, 100)\n",
    "        MAP_optimizer.step()\n",
    "        MAP_optimizer.zero_grad()\n",
    "    return img_ano"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31979bb",
   "metadata": {},
   "source": [
    "## Plot for weight vs epsilon(lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d620e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_vals = (np.linspace(0.5,10,40)).tolist()\n",
    "num_samples = 100\n",
    "n_latent_samples = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d84c7267",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "90476df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.L1Loss(reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bff8c4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = loss(img[0].view(-1, 128*128), restored[0].view(-1, 128*128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b6649f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2165.020664772648"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ll.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3f1b9c61",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Ž         | 3/100 [00:06<03:26,  2.12s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-ae067efcc2e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mdecoded_mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_latent_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mrecon_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_cov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvae_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mdecoded_mu\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mrecon_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mdecoded_mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoded_mu\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mn_latent_samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/torch/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/31_1_22/vae.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreparameterize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/31_1_22/vae.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, z)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/torch/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/torch/lib/python3.9/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/torch/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/31_1_22/vae.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshortcut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/torch/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/torch/lib/python3.9/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/torch/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/torch/lib/python3.9/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/torch/lib/python3.9/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    437\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 439\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    440\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cumerrlist=[]\n",
    "for j in range(len(lambda_vals)):\n",
    "    lambval = lambda_vals[j]\n",
    "    cumerr = 0\n",
    "    for i in tqdm(range(num_samples)):\n",
    "        img = load_training_image()\n",
    "        img = img.to(device)\n",
    "        \n",
    "        decoded_mu = torch.zeros(img.size())\n",
    "        for s in range(n_latent_samples):\n",
    "            recon_batch, z_mean, z_cov, res = vae_model(img.double())\n",
    "            decoded_mu += np.array([1 * recon_batch[i].detach().cpu().numpy() for i in range(img.size()[0])])\n",
    "        decoded_mu = decoded_mu / n_latent_samples\n",
    "        \n",
    "        img = img.squeeze(1)\n",
    "        decoded_mu = decoded_mu.squeeze(1)\n",
    "        restored = map_restoration(input_img=img, dec_mu=decoded_mu, riter=100, weight=lambval, step_size=0.01)\n",
    "        \n",
    "        #err = torch.sum(torch.abs(restored - img))\n",
    "        with torch.no_grad():\n",
    "            err = loss(img, restored)\n",
    "        cumerr += err.item()\n",
    "    cumerr = cumerr / num_samples\n",
    "    cumerrlist.append(cumerr)\n",
    "    print(lambval, cumerr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f0abaece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb617f6d550>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lambda_vals[0:24],cumerrlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9d66b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
