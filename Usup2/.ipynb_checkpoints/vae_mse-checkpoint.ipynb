{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a38165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision as vision\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70b859b",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dim = 60\n",
    "learning_rate = 5e-4\n",
    "batch_size=16\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52538aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class q_zx(nn.Module):\n",
    "    def __init__(self, z_dims, in_channels=1, channels=[32, 64, 64]):\n",
    "        super(q_zx, self).__init__()\n",
    "        modules = []\n",
    "        c1 = self._convblock(1, channels[0], 3, padding='same', bias=True)\n",
    "        modules.append(*c1)\n",
    "        c2 = self._convblock(channels[0], channels[1], 3, padding='same', bias=True)\n",
    "        modules.append(*c2)\n",
    "        c3 = self._convblock(channels[1], channels[2], 3, padding='same', bias=True)\n",
    "        modules.append(*c3)\n",
    "        self.model = nn.Sequential(*modules)\n",
    "        self.mu_fc = nn.Linear(64*64*64, z_dims)\n",
    "        self.logvar_fc = nn.Linear(64*64*64, z_dims)\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "    def _convblock(self, in_channels, out_channels, kernel_size, padding, bias):\n",
    "        modules = []\n",
    "        modules.append(\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(in_channels=in_channels,\n",
    "                         out_channels=out_channels,\n",
    "                         kernel_size=kernel_size,\n",
    "                         padding=padding,\n",
    "                         bias=bias),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        )\n",
    "        return modules\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = self.flatten(x)\n",
    "        mu_z = self.mu_fc(x)\n",
    "        logvar_z = self.logvar_fc(x)\n",
    "        return mu_z, logvar_z\n",
    "    \n",
    "class p_xz(nn.Module):\n",
    "    def __init__(self, z_dims, out_channels=1, channels=[48, 90, 90],batch_size=1):\n",
    "        super(p_xz, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.fc = nn.Linear(z_dims, 64*64*48)\n",
    "        self.relu_fc = nn.ReLU()\n",
    "        \n",
    "        modules = []\n",
    "        self.c1 = self._convblock(48, channels[0], kernel_size=3, padding='same', bias=True)\n",
    "        modules.append(*self.c1)\n",
    "        self.c2 = self._convblock(channels[0], channels[1], kernel_size=3, padding='same', bias=True)\n",
    "        modules.append(*self.c2)\n",
    "        self.c3 = self._convblock(channels[1], channels[2], kernel_size=3, padding='same', bias=True)\n",
    "        modules.append(*self.c3)\n",
    "        self.c = nn.Sequential(*modules)\n",
    "        \n",
    "        self.mu_conv = nn.Conv2d(in_channels=channels[2], out_channels=out_channels, kernel_size=3, padding='same', bias=False)\n",
    "        \n",
    "        \n",
    "    def _convblock(self, in_channels, out_channels, kernel_size, padding, bias):\n",
    "        modules = []\n",
    "        modules.append(\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(in_channels=in_channels,\n",
    "                          out_channels=out_channels,\n",
    "                          kernel_size=kernel_size,\n",
    "                          padding=padding,\n",
    "                          bias=bias),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        )\n",
    "        return modules\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = self.relu_fc(x)\n",
    "        x = x.view(-1, 48, 64, 64)\n",
    "        x = self.c(x)\n",
    "        image = self.mu_conv(x)\n",
    "        return self.relu_fc(image)\n",
    "    \n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, z_dims=60):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = q_zx(z_dims=z_dims)\n",
    "        self.decoder = p_xz(z_dims=z_dims, batch_size=batch_size)\n",
    "        \n",
    "    def encode(self, x):\n",
    "        mu_z, logvar_z = self.encoder(x)\n",
    "        # mu_z = (1, z_dims)\n",
    "        # logvar_z = (1, z_dims)\n",
    "        return mu_z, logvar_z\n",
    "    \n",
    "    def decode(self, x):\n",
    "        mu_x = self.decoder(x)\n",
    "        # mu_x = (batch, 1, 64, 64)\n",
    "        # logvar_x = (batch, 1, 64, 64)\n",
    "        return mu_x\n",
    "    \n",
    "    def sample(self, mu_z, logvar_z):\n",
    "        std = torch.exp(0.5*logvar_z)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu_z + eps*std\n",
    "    \n",
    "    def loss_function(self, mu_x, x, mu_z, logvar_z):\n",
    "        #mu_x = torch.flatten(mu_x, start_dim = 1)\n",
    "        #logvar_x = torch.flatten(logvar_x, start_dim=1)\n",
    "        BCE = F.mse_loss(mu_x, x, reduction='sum')\n",
    "        KLD = torch.mean(-0.5 * torch.sum(1 + logvar_z - mu_z.pow(2) - logvar_z.exp()))\n",
    "        return loss_rec + KLD\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu_z, logvar_z = self.encode(x)\n",
    "        z_sampled = self.sample(mu_z, logvar_z)\n",
    "        mu_x = self.decode(z_sampled)\n",
    "        return mu_z, logvar_z, mu_x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db75958",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((64,64)),\n",
    "        transforms.Grayscale(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            0.5, 0.5\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataset = vision.datasets.ImageFolder('/home/Student/s4606685/summer_research/oasis-3/png_data', transform=transform)\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5489467f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_sample():\n",
    "    train_loader2 = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "    loader = enumerate(train_loader2)\n",
    "    data = next(loader)\n",
    "    return data[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c92a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE()\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc28237",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        mu_z, logvar_z, mu_x = model(data)\n",
    "        loss = model.loss_function(mu_x, data, mu_z, logvar_z)\n",
    "        loss.backward()\n",
    "        train_loss += loss.mean().item()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 1200 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                       100. * batch_idx / len(train_loader),\n",
    "                       loss.item() / len(data)))\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "        epoch, train_loss / len(train_loader.dataset)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
